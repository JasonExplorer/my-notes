## 1、电商业务简介
### 1.1 电商业务流程
电商的业务流程可以以一个普通用户的浏览足迹为例进行说明，用户点开电商首页开始浏览，可能会通过分类查询也可能通过全文搜索寻找自己中意的商品，这些商品无疑都是存储在后台的管理系统中的。

- 当用户寻找到自己中意的商品，可能会想要购买，将商品添加到购物车后发现需要登录，登录后对商品进行结算，这时候购物车的管理和商品订单信息的生成都会对业务数据库产生影响，会生成相应的订单数据和支付数据。

- 订单正式生成之后，还会对订单进行跟踪处理，直到订单全部完成。

- 电商的主要业务流程包括用户前台浏览商品时的商品详情的管理，用户商品加入购物车进行支付时用户个人中心&支付服务的管理，用户支付完成后订单后台服务的管理，这些流程涉及到了十几个甚至几十个业务数据表，甚至更多。

### 1.2 电商常识
#### 1.2.1 SKU和SPU
SKU = Stock Keeping Unit（库存量基本单位）。现在已经被引申为产品统一编号的简称，每种产品均对应有唯一的SKU号。

- SPU（Standard Product Unit）：是商品信息聚合的最小单位，是一组可复用、易检索的标准化信息集合。

其实，SPU 就是一类商品（比如 三星S23），而 SKU 是一种具体型号的商品（比如 三星S23 8+256 悠远黑）。

#### 1.2.2 平台属性和销售属性
**(1) 平台属性**
![platform-attr.png](img%2Fbiz%2Fplatform-attr.png)

**(2) 商品属性**
![goods-attr.png](img%2Fbiz%2Fgoods-attr.png)

## 2、业务数据介绍
以下为本电商数仓系统涉及到的业务数据表结构关系。这34个表以订单表、用户表、SKU商品表、活动表和优惠券表为中心，延伸出了优惠券领用表、支付流水表、活动订单表、订单详情表、订单状态表、商品评论表、编码字典表退单表、SPU商品表等，用户表提供用户的详细信息，支付流水表提供该订单的支付详情，订单详情表提供订单的商品数量等情况，商品表给订单详情表提供商品的详细信息。这里以此34个表为例，实际项目中，业务数据库中表格远远不止这些。
### 2.1.1 活动信息表（activity_info）
### 2.1.2 活动规则表（activity_rule）
### 2.1.3 活动商品关联表（activity_sku）
### 2.1.4 平台属性表（base_attr_info）
### 2.1.5 平台属性值表（base_attr_value）
### 2.1.6 一级分类表（base_category1）
### 2.1.7 二级分类表（base_category2）
### 2.1.8 三级分类表（base_category3）
### 2.1.9 字典表（base_dic）
### 2.1.10 省份表（base_province）
### 2.1.11 地区表（base_region）
### 2.1.12 品牌表（base_trademark）
### 2.1.13 购物车表（cart_info）
### 2.1.14 评价表（comment_info）
### 2.1.15 优惠券信息表（coupon_info）
### 2.1.16 优惠券优惠范围表（coupon_range）
### 2.1.17 优惠券领用表（coupon_use）
### 2.1.18 收藏表（favor_info）
### 2.1.19 订单明细表（order_detail）
### 2.1.20 订单明细活动关联表（order_detail_activity）
### 2.1.21 订单明细优惠券关联表（order_detail_coupon）
### 2.1.22 订单表(order_info）
### 2.1.23 退单表（order_refund_info）
### 2.1.24 订单状态流水表（order_status_log）
### 2.1.25 支付表（payment_info）
### 2.1.26 退款表（refund_payment）
### 2.1.27 SKU平台属性表（sku_attr_value）
### 2.1.28 SKU信息表（sku_info）
### 2.1.29 SKU销售属性表（sku_sale_attr_value）
### 2.1.30 SPU信息表（spu_info）
### 2.1.31 SPU销售属性表（spu_sale_attr）
### 2.1.32 SPU销售属性值表（spu_sale_attr_value）
### 2.1.33 用户地址表（user_address）
### 2.1.34 用户信息表（user_info）

**电商业务表结构：**
![mall-biz-table.png](img%2Fbiz%2Fmall-biz-table.png)


**后台管理表结构：**
![mall-sys-table.png](img%2Fbiz%2Fmall-sys-table.png)

## 3、业务数据采集模块

![biz-data-collect.png](img%2Fbiz%2Fbiz-data-collect.png)

我们的项目架构图中，业务数据是通过两方面采集到离线数仓中的：需要增量同步的数据通过 Maxwell（可以实时捕获和传输MySQL数据库的变更操作，适合增量同步） 发送到 Kafka 集群，然后再通过 flume 发送到离线数仓当中；而 DataX 是每天把全量的数据发送到集群当中的。

而实时数仓中的业务数据源也是由 Maxwell 发送到 Kafka 集群，然后 Flink 直接从 Kafka 读取的。

### 3.1、采集通道 Maxwell 配置
1. 开启 mysql binlog
在 /etc/my.cnf 中添加以下配置：
```bash
server-id=1
log-bin=mysql-bin
# maxwell要求binlog模式必须为 row
binlog_format=row
binlog-do-db=gmall

```
2. 修改 maxwell 配置文件
   我们这里通过配置文件来启动 maxwell：

```properties
# tl;dr config
log_level=info
 
#Maxwell数据发送目的地，可选配置有stdout|file|kafka|kinesis|pubsub|sqs|rabbitmq|redis
producer=kafka
#目标Kafka集群地址
kafka.bootstrap.servers=hadoop102:9092,hadoop103:9092,hadoop104:9092
#目标Kafka topic，可静态配置，例如:maxwell，也可动态配置，例如：%{database}_%{table},相当于给每张表创
建一个 topic
kafka_topic=maxwell
# kafka 分区规则 按照数据库分区
#producer_partition_by=database
 
# mysql 相关配置
host=hadoop102
user=maxwell
password=123456
```

这里的 kafka_topic 测试完后需要改成我们项目指定的 topic_db

`bin/maxwell --config config.properties`

3. 启动 Kafka 消费者
`bin/kafka-console-consumer.sh --bootstrap-server hadoop102:9092 --topic maxwell`

4. 模拟数据生成
```bash
cd /opt/module/db_log/
java -jar gmall2020-mock-db-2021-11-14.jar
```
5. 查看结果：
我们可以看到，我们在 hadoop103 上开启的 Kafka 消费者的控制台，输出了抓取到所有日志：
![test-result.png](img%2Fbiz%2Ftest-result.png)
   而且此刻的 mysql 的 binlog 文件的大小也在急剧增加：
![mysql-binlog.png](img%2Fbiz%2Fmysql-binlog.png)

到这里，我们的 maxwell 的业务数据采集通道已经打通了。

6. 编写 maxwell 启停脚本
```bash
#!/bin/bash
 
MAXWELL_HOME=/opt/module/maxwell-1.29.2
 
status_maxwell(){
    result=`ps -ef | grep com.zendesk.maxwell.Maxwell | grep -v grep | wc -l`
    return $result
}
 
 
start_maxwell(){
    status_maxwell
    if [[ $? -lt 1 ]]; then
        echo "启动Maxwell"
        $MAXWELL_HOME/bin/maxwell --config $MAXWELL_HOME/config.properties --daemon
    else
        echo "Maxwell正在运行"
    fi
}
 
 
stop_maxwell(){
    status_maxwell
    if [[ $? -gt 0 ]]; then
        echo "停止Maxwell"
        ps -ef | grep com.zendesk.maxwell.Maxwell | grep -v grep | awk '{print $2}' | xargs kill -9
    else
        echo "Maxwell未在运行"
    fi
}
 
 
case $1 in
    start )
        start_maxwell
    ;;
    stop )
        stop_maxwell
    ;;
    restart )
       stop_maxwell
       start_maxwell
    ;;
esac

```

## 总结
至此，我们的日志数据采集（用户行为日志和业务日志）平台都已经搭建完毕了，我们的日志数据都已经汇总到了 Kafka，接下来我们的离线数仓和实时数仓只需要直接去 Kafka 读取即可。
![all-design.png](img%2Fbiz%2Fall-design.png)


————————————————

版权声明：本文为博主原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接和本声明。

原文链接：https://blog.csdn.net/m0_64261982/article/details/136153317